{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üêÑ Animal Image Classifier - Buffalo vs. Cattle\n",
        "\n",
        "This notebook loads a fine-tuned MobileNetV2 model( which was saved after training) to classify animal images as either **Buffalo** or **Cattle**.  \n",
        "It includes image quality checks for **blurriness** and **cropping**, ensuring only valid images are evaluated.  \n",
        "Predictions are generated for a folder of images and saved as a CSV with confidence scores and quality flags.\n"
      ],
      "metadata": {
        "id": "b54pMQjqT7CE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Setup\n",
        "\n",
        "This cell imports all the necessary libraries for image processing, model loading, and data handling. It includes libraries like `os`, `cv2`, `torch`, `torchvision`, `PIL`, `numpy`, `pandas`, and `tqdm`."
      ],
      "metadata": {
        "id": "YrV17tMKSl-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0ZHBYj4zRpGR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract Dataset\n",
        "\n",
        "This cell extracts the animal dataset from a zip file located at certain path into a directory named `dataset`. The variable `data` is set to the path of the extracted dataset."
      ],
      "metadata": {
        "id": "5Cvcz7DpS2bI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lapMdU_NSnQF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "with zipfile.ZipFile(\"/content/sample_data/animal_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")\n",
        "data = './dataset'"
      ],
      "metadata": {
        "id": "xrWp7qZKfGrP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model and Define Transforms\n",
        "\n",
        "This cell defines the `load_model` function to load a pre-trained MobileNetV2 model and adapt it for binary classification. It also defines the image `transform` to resize, convert to tensor, and normalize images for the model. The `class_names` list is defined for the two classes: 'Buffalo' and 'Cattle'."
      ],
      "metadata": {
        "id": "odN9kDDcTASp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Load Model\n",
        "def load_model(model_path):\n",
        "    model = models.mobilenet_v2(weights=None)\n",
        "    model.classifier[1] = nn.Linear(model.last_channel, 2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# 3. Define Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class_names = ['Buffalo', 'Cattle']\n"
      ],
      "metadata": {
        "id": "m6Q0d_ZWRvcN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Functions\n",
        "\n",
        "This cell defines two utility functions:\n",
        "- `is_blurry`: Checks if an image is blurry using the Laplacian variance method.\n",
        "- `is_cropped`: Checks if an image is potentially cropped by analyzing the largest contour's area ratio.\n",
        "\n",
        "It also defines two prediction functions:\n",
        "- `predict_image`: Predicts the class and confidence for a single image.\n",
        "- `predict_folder`: Predicts the class and status (Blurry, Cropped, or Class prediction with confidence) for all images in a given folder and returns the results as a pandas DataFrame."
      ],
      "metadata": {
        "id": "3J-HkDLHTOOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kdT4J0DrEcVy"
      },
      "outputs": [],
      "source": [
        "# 4. Utility Functions\n",
        "def is_blurry(image, threshold=100):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    return laplacian_var < threshold\n",
        "\n",
        "def is_cropped(image, min_area_ratio=0.5):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return True\n",
        "    max_contour = max(contours, key=cv2.contourArea)\n",
        "    area_ratio = cv2.contourArea(max_contour) / (image.shape[0] * image.shape[1])\n",
        "    return area_ratio < min_area_ratio\n",
        "\n",
        "# 5. Predict a Single Image\n",
        "def predict_image(model, image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        prob = torch.nn.functional.softmax(output[0], dim=0)\n",
        "        predicted_class = class_names[torch.argmax(prob).item()]\n",
        "        confidence = prob.max().item()\n",
        "    return predicted_class, confidence, confidence # Return confidence as well\n",
        "\n",
        "# 6. Predict Images in Folder\n",
        "def predict_folder(model, image_folder, confidence_threshold=0.7): # Add confidence_threshold\n",
        "    results = []\n",
        "    for img_name in tqdm(os.listdir(image_folder)):\n",
        "        if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
        "            img_path = os.path.join(image_folder, img_name)\n",
        "            image_cv = cv2.imread(img_path)\n",
        "\n",
        "            if is_blurry(image_cv):\n",
        "                status = \"Blurry\"\n",
        "            elif is_cropped(image_cv):\n",
        "                status = \"Cropped\"\n",
        "            else:\n",
        "                label, confidence, _ = predict_image(model, img_path) # Get confidence\n",
        "                if confidence < confidence_threshold: # Check confidence\n",
        "                    status = \"Not a valid animal image\"\n",
        "                else:\n",
        "                    status = f\"{label} ({confidence*100:.2f}%)\"\n",
        "\n",
        "            results.append((img_name, status))\n",
        "\n",
        "    print() # Add a new line after the tqdm loop\n",
        "    return pd.DataFrame(results, columns=[\"Image\", \"Prediction\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Example\n",
        "\n",
        "This cell demonstrates how to use the defined functions. It loads the pre-trained model, runs the `predict_folder` function on the \"Cattle\" images in the extracted dataset, saves the predictions to a CSV file named `predictionsreport.csv`, and prints the head of the resulting DataFrame."
      ],
      "metadata": {
        "id": "is5bYanBTbg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Run Example\n",
        "model = load_model(\"/content/sample_data/best_model.pth\")\n",
        "df = predict_folder(model, \"/content/dataset/animal_dataset/Cattle\")\n",
        "df.to_csv(\"predictionsreport.csv\", index=False)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xfhw9BcRe59",
        "outputId": "afa18907-6325-46c2-9c79-a217d8b6462d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 203/203 [00:10<00:00, 18.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              Image                Prediction\n",
            "0  page19_img1.jpeg           Cattle (97.27%)\n",
            "1  page22_img2.jpeg                    Blurry\n",
            "2  page22_img1.jpeg          Buffalo (70.38%)\n",
            "3  page40_img2.jpeg           Cattle (92.66%)\n",
            "4  page40_img3.jpeg  Not a valid animal image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}